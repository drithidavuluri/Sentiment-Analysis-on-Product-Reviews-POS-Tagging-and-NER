# -*- coding: utf-8 -*-
"""Task-2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/task-2-345b3038-ce50-4a71-a30b-361e8850a850.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240220/auto/storage/goog4_request%26X-Goog-Date%3D20240220T163224Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0e4a1c9bc999362cfed2de0414bc59f50cfc236c1c59e25d4332b5db5c922bd863b8f15e451e22cb00ad04989235f74a225f006c31a2579d1db628aab07718f4b86f98b316779a3dd90fe9615596f406f073074a084a7d5a9fa0778270e8ee6ddeca2b9fe6575a851dbf1ac077e609cd0e3b2eae9c3557f6588541e0d071c460548d5410d070df9eea37494de45265699ef3188680f57f850291b8452781493af665723e30e198a2e557154d928a0e7eed9f54acb6a8293bd5feb7e6326cfea80f85f5e0e3b5458fc068700a07a5b8ba4db1efa6c86e511b4b36cead6ae223edb1f1d1d83f275b2e4700d8bf2ae517d33ed5404d0b4a8da49fd0f81b4d287251
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'nlu-project1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4462342%2F7654130%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240220%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240220T163223Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9db9d70e205f57fa5008a7e0ef17d93f9ece49188fed9ecc39e87ce55bf7f2e4f4a2d384f200588365e920e64c87cadbf369c070520bb3d5315927b2d4a2d601506cf6d715e529b978d02bd6a8a8e99c481b061b1eaf1e5fe9d2c3a4c3cff9554c59d458f6462ed3bdc6b679d8a60b83e4e4542d1d88932a437f607d29b4e5145d9fe7c1916a68a437d039951ddc01d9d429bf4561edc1398b8ea17b67c9142a8d77f04f0d34547035095dfe24fda1498ab6be12e1d8b9a62c285a042f7a7b0958014982dc09bf24b64c09d7cb6a7a45ae5011994e522c2ed3f7012023da137c34ccf35f8c162cecc9a87c9ff24bc938d2efd649a14d7b44816a3d0d4245ac1f,sampled-nlu1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4464009%2F7656491%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240220%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240220T163224Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D41afeedd7d340eca845b1b2d34cfeb9cb078814aa1147b189e9bb710d0539ed308c9ef6a716310b515868338568e1999638751861c94798f91b80cf91dde8f7e08e535e6a0e8720a118d8584687b9dcde2fbd7822e5fdc7c5817ce0bba9446ed8c804685073489052f5b0018a37b332711e437d4fdcd525670d6d7d8145f2672e94e2901804dbb4a81f3d9c12beac4e3281ac60700e7b873e4c6b3b4932d8a2593849afd3c7ac32100006614c9272f58c0c22bcc29c12d1f2234f59aa4b4111b971aa01a2f220be299ad2718c274021d5b277b0ce7097c8d51d5a141e448d85c7af2b37d561f025204645279afaa2c2adb3d416990cb81e1a9a89191f8e9f5c6,stanford-lib:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4469983%2F7664996%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240220%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240220T163224Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D500303c52a2180e4e04d8cc4a8a867ceb42075491c745e4d23ce4ed8cb56c9641056cb998830790599492070cb773287f59412398607c94b50a1150183daa18bb26b36221c8456ae2e325572d3046201e317c473a1577005057000258859aa16d5243c7b89a8ed77d325c08f7947a9271d271329aeb09807f0f9c059fd25effd15c1c8d760b8903eb5828f61b1e2b86a94502ef29592cf2746cba92ce7bae2bef84f21e0da7a44440e8c9854e43241a8d4e42481155c7a762c4e462e5dbbd54de7ac872a9173562460819d9d6302d6bca6983b4e3f003a4a418df5e293396cf7aded83f874a2776ddedbd8eb2f817221de5155081734d48aa2757008a4a14136'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""# Data Preperation"""

import os
import json
import pandas as pd
import random
from sklearn.model_selection import train_test_split

folder_path = '/kaggle/input/nlu-project1'
sampled_data = []
samples_per_file = 2000

random_seed = 42

for filename in os.listdir(folder_path):
    if filename.endswith('.json'):
        file_path = os.path.join(folder_path, filename)

        with open(file_path, 'r', encoding='utf-8') as file:
            current_samples = [json.loads(line) for line in file]

        sampled_entries = random.sample(current_samples, min(samples_per_file, len(current_samples)))
        sampled_data.extend(sampled_entries)

sampled_df = pd.DataFrame(sampled_data)
sampled_df.to_csv('/kaggle/working/sampled_dataset.csv', index=False)

df=pd.read_csv('/kaggle/working/sampled_dataset.csv')
df

df.info()

overall_counts = df['overall'].value_counts()
print(overall_counts)

folder_path = '/kaggle/input/nlu-project1'

sampled_data = []
samples_per_rating = 400  # No.of samples per rating in each file

random_seed = 42

for filename in os.listdir(folder_path):
    if filename.endswith('.json'):
        file_path = os.path.join(folder_path, filename)

        with open(file_path, 'r', encoding='utf-8') as file:
            current_samples = [json.loads(line) for line in file]

        ratings_count = {1.0: 0, 2.0: 0, 3.0: 0, 4.0: 0, 5.0: 0}
        sampled_entries = []

        for entry in current_samples:
            rating = entry['overall']
            if ratings_count[rating] < samples_per_rating:
                sampled_entries.append(entry)
                ratings_count[rating] += 1

        sampled_data.extend(sampled_entries)

sampled_df = pd.DataFrame(sampled_data)
sampled_df.to_csv('/kaggle/working/sampled_dataset.csv', index=False)

df=pd.read_csv('/kaggle/working/sampled_dataset.csv')
df

df.info()

overall_counts = df['overall'].value_counts()
print(overall_counts)

"""# Text preprocessing"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

columns_to_remove = ['reviewTime', 'reviewerID', 'style', 'reviewerName','unixReviewTime', 'vote', 'image']
df = df.drop(columns=columns_to_remove)

nltk.download('stopwords')
nltk.download('punkt')

def preprocess_text(text):
    if pd.notna(text):
        # 1. Lowercase
        text = text.lower()

        # 2. Remove special characters and digits
        text = re.sub(r'[^a-z\s]', '', text)

        # 3. Tokenization
        tokens = word_tokenize(text)

        # 4. Remove stopwords
        stop_words = set(stopwords.words('english'))
        important_words = ['not', 'very', 'extremely', 'highly', 'really', 'no', 'never',
                           'good', 'great', 'bad', 'poor', 'excellent', 'awful',
                           'truly', 'certainly', 'absolutely', 'but', 'however', 'although',
                           'better', 'worse', 'more', 'less', 'now', 'today', 'currently',
                           'many', 'few', 'several']
        stop_words.difference_update(important_words) # remove stopwords other than some mention imp words

        tokens = [token for token in tokens if token not in stop_words]

        # 5. Stemming
        stemmer = PorterStemmer()
        tokens = [stemmer.stem(token) for token in tokens]

        processed_text = ' '.join(tokens)

        return processed_text
    else:
        return ''

df['processed_reviewText'] = df['reviewText'].apply(preprocess_text)
df['processed_summary'] = df['summary'].apply(preprocess_text)

df.to_csv('/kaggle/working/df_processed.csv', index=False)

df=pd.read_csv('/kaggle/input/sampled-nlu1/df_processed (1).csv')

df

"""# TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud
import matplotlib.pyplot as plt

corpus = df['processed_reviewText'].tolist()

df['processed_reviewText'].fillna('', inplace=True)
df['processed_summary'].fillna('', inplace=True)

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_reviewText'].tolist()

    tfidf_vectorizer = TfidfVectorizer()
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)

    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})

    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)
    top_terms = tfidf_scores_df.head(10)['Term'].tolist()
    print(f"\nTop 10 terms for rating {rating}:\n", top_terms)

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_summary'].tolist()

    tfidf_vectorizer = TfidfVectorizer()
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})

    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)
    top_terms = tfidf_scores_df.head(10)['Term'].tolist()
    print(f"\nTop 10 terms for rating {rating}:\n", top_terms)

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_reviewText'].tolist()

    tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2))

    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)

    tfidf_scores_df = pd.DataFrame({'Bigram': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})
    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)

    top_bigrams = tfidf_scores_df.head(10)['Bigram'].tolist()
    print(f"\nTop 10 bigrams for rating {rating}:\n", top_bigrams)

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_summary'].tolist()

    tfidf_vectorizer = TfidfVectorizer(ngram_range=(2, 2))
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)

    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Bigram': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})

    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)
    top_bigrams = tfidf_scores_df.head(10)['Bigram'].tolist()
    print(f"\nTop 10 bigrams for rating {rating}:\n", top_bigrams)

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_reviewText'].tolist()

    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))

    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})

    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)

    top_terms = tfidf_scores_df.head(10)['Term'].tolist()
    print(f"\nTop 10 terms (unigrams and bigrams) for rating {rating}:\n", top_terms)

unique_ratings = df['overall'].unique()

fig, axes = plt.subplots(nrows=len(unique_ratings), ncols=2, figsize=(15, 8), sharex=True)

for i, rating in enumerate(unique_ratings):
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_reviewText'].tolist()

    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})
    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)

    top_terms = tfidf_scores_df.head(10)['Term'].tolist()

    wordcloud = WordCloud(width=400, height=200, max_words=50, background_color='white').generate_from_frequencies(dict(zip(top_terms, tfidf_scores_df.head(10)['TF-IDF Score'].tolist())))
    axes[i, 0].imshow(wordcloud, interpolation='bilinear')
    axes[i, 0].set_title(f"Word Cloud for rating {rating} (Unigrams & Bigrams)")
    axes[i, 0].axis("off")

    axes[i, 1].barh(tfidf_scores_df.head(10)['Term'], tfidf_scores_df.head(10)['TF-IDF Score'], color='skyblue')
    axes[i, 1].set_title(f"Top 10 terms for rating {rating}")
    axes[i, 1].set_xlabel("TF-IDF Score")

plt.tight_layout()
plt.show()

unique_ratings = df['overall'].unique()

for rating in unique_ratings:
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_summary'].tolist()
    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))

    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)
    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)

    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})
    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)
    top_terms = tfidf_scores_df.head(10)['Term'].tolist()
    print(f"\nTop 10 terms (unigrams and bigrams) for rating {rating}:\n", top_terms)

unique_ratings = df['overall'].unique()

fig, axes = plt.subplots(nrows=len(unique_ratings), ncols=2, figsize=(15, 8), sharex=True)

for i, rating in enumerate(unique_ratings):
    subset_df = df[df['overall'] == rating]
    corpus = subset_df['processed_summary'].tolist()
    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))
    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)

    feature_names = tfidf_vectorizer.get_feature_names_out()
    total_tfidf_scores = tfidf_matrix.sum(axis=0)
    tfidf_scores_df = pd.DataFrame({'Term': feature_names, 'TF-IDF Score': total_tfidf_scores.tolist()[0]})

    tfidf_scores_df = tfidf_scores_df.sort_values(by='TF-IDF Score', ascending=False)
    top_terms = tfidf_scores_df.head(10)['Term'].tolist()

    wordcloud = WordCloud(width=400, height=200, max_words=50, background_color='white').generate_from_frequencies(dict(zip(top_terms, tfidf_scores_df.head(10)['TF-IDF Score'].tolist())))

    axes[i, 0].imshow(wordcloud, interpolation='bilinear')
    axes[i, 0].set_title(f"Word Cloud for rating {rating} (Unigrams & Bigrams)")
    axes[i, 0].axis("off")

    axes[i, 1].barh(tfidf_scores_df.head(10)['Term'], tfidf_scores_df.head(10)['TF-IDF Score'], color='skyblue')
    axes[i, 1].set_title(f"Top 10 terms for rating {rating}")
    axes[i, 1].set_xlabel("TF-IDF Score")

plt.tight_layout()
plt.show()

df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)

print(f"Train set size: {len(df_train)} samples")
print(f"Validation set size: {len(df_val)} samples")

"""# 5- class classification"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn import metrics
from scipy.sparse import hstack
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""## Naive Bayes classifier.

bow + reviewText
"""

vectorizer = CountVectorizer()

X_train_bow = vectorizer.fit_transform(df_train['processed_reviewText'])
X_val_bow = vectorizer.transform(df_val['processed_reviewText'])

gnb = GaussianNB()
gnb.fit(X_train_bow.toarray(), df_train['overall'])

y_pred_gaussian_1 = gnb.predict(X_val_bow.toarray())
accuracy_gaussian_1 = metrics.accuracy_score(df_val['overall'], y_pred_gaussian_1)

mnb = MultinomialNB()
mnb.fit(X_train_bow, df_train['overall'])

y_pred_multinomial_1 = mnb.predict(X_val_bow)
accuracy_multinomial_1 = accuracy_score(df_val['overall'], y_pred_multinomial_1)

print("Gaussian Naive Bayes Accuracy on Validation Set:", accuracy_gaussian_1)
print("Multinomial Naive Bayes Accuracy on Validation Set:", accuracy_multinomial_1)

print("Gaussian Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_gaussian_1))
print("Precision:", precision_score(df_val['overall'], y_pred_gaussian_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gaussian_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gaussian_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gaussian_1))

print("\nMultinomial Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_multinomial_1))
print("Precision:", precision_score(df_val['overall'], y_pred_multinomial_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_multinomial_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_multinomial_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_multinomial_1))

"""bow + summary"""

vectorizer = CountVectorizer()

X_train_bow = vectorizer.fit_transform(df_train['processed_summary'])
X_val_bow = vectorizer.transform(df_val['processed_summary'])

gnb = GaussianNB()
gnb.fit(X_train_bow.toarray(), df_train['overall'])

y_pred_gaussian_2 = gnb.predict(X_val_bow.toarray())
accuracy_gaussian_2 = metrics.accuracy_score(df_val['overall'], y_pred_gaussian_2)

mnb = MultinomialNB()
mnb.fit(X_train_bow, df_train['overall'])

y_pred_multinomial_2 = mnb.predict(X_val_bow)
accuracy_multinomial_2 = accuracy_score(df_val['overall'], y_pred_multinomial_2)

print("Gaussian Naive Bayes Accuracy on Validation Set:", accuracy_gaussian_2)
print("Multinomial Naive Bayes Accuracy on Validation Set:", accuracy_multinomial_2)

print("Gaussian Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_gaussian_2))
print("Precision:", precision_score(df_val['overall'], y_pred_gaussian_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gaussian_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gaussian_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gaussian_2))

print("\nMultinomial Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_multinomial_2))
print("Precision:", precision_score(df_val['overall'], y_pred_multinomial_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_multinomial_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_multinomial_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_multinomial_2))

"""tfidf + review + summary"""

vectorizer_review = TfidfVectorizer()
vectorizer_summary = TfidfVectorizer()

X_train_tfidf_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_val_tfidf_review = vectorizer_review.transform(df_val['processed_reviewText'])

X_train_tfidf_summary = vectorizer_summary.fit_transform(df_train['processed_summary'])
X_val_tfidf_summary = vectorizer_summary.transform(df_val['processed_summary'])

X_train_tfidf_combined = hstack([X_train_tfidf_review, X_train_tfidf_summary])
X_val_tfidf_combined = hstack([X_val_tfidf_review, X_val_tfidf_summary])

gnb = GaussianNB()
gnb.fit(X_train_tfidf_combined.toarray(), df_train['overall'])

y_pred_gaussian_3 = gnb.predict(X_val_tfidf_combined.toarray())
accuracy_gaussian_3 = accuracy_score(df_val['overall'], y_pred_gaussian_3)

mnb = MultinomialNB()
mnb.fit(X_train_tfidf_combined, df_train['overall'])

y_pred_multinomial_3 = mnb.predict(X_val_tfidf_combined)
accuracy_multinomial_3 = accuracy_score(df_val['overall'], y_pred_multinomial_3)

print("Gaussian Naive Bayes Accuracy with TF-IDF on Validation Set:", accuracy_gaussian_3)
print("Multinomial Naive Bayes Accuracy with TF-IDF on Validation Set:", accuracy_multinomial_3)

print("Gaussian Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_gaussian_3))
print("Precision:", precision_score(df_val['overall'], y_pred_gaussian_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gaussian_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gaussian_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gaussian_3))

print("\nMultinomial Naive Bayes Metrics:")
print("Accuracy:", accuracy_score(df_val['overall'], y_pred_multinomial_3))
print("Precision:", precision_score(df_val['overall'], y_pred_multinomial_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_multinomial_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_multinomial_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_multinomial_3))

"""## Decision Tree

bow + reviewText
"""

vectorizer_review = CountVectorizer()

X_train_bow_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_val_bow_review = vectorizer_review.transform(df_val['processed_reviewText'])

dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy.fit(X_train_bow_review, df_train['overall'])

y_pred_entropy_1 = dt_entropy.predict(X_val_bow_review)
accuracy_entropy_1 = metrics.accuracy_score(df_val['overall'], y_pred_entropy_1)

dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini.fit(X_train_bow_review, df_train['overall'])

y_pred_gini_1 = dt_gini.predict(X_val_bow_review)
accuracy_gini_1 = metrics.accuracy_score(df_val['overall'], y_pred_gini_1)

print("Decision Tree Accuracy with Entropy on Validation Set:", accuracy_entropy_1)
print("Decision Tree Accuracy with Gini on Validation Set:", accuracy_gini_1)

print("\nDecision Tree Metrics (Entropy):")
print("Accuracy:", accuracy_entropy_1)
print("Precision:", precision_score(df_val['overall'], y_pred_entropy_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_entropy_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_entropy_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_entropy_1))

print("\nDecision Tree Metrics (Gini):")
print("Accuracy:", accuracy_gini_1)
print("Precision:", precision_score(df_val['overall'], y_pred_gini_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gini_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gini_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gini_1))

"""bow + summary"""

vectorizer_summary = CountVectorizer()

X_train_bow_summary = vectorizer_summary.fit_transform(df_train['processed_summary'])
X_val_bow_summary = vectorizer_summary.transform(df_val['processed_summary'])

dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy.fit(X_train_bow_summary, df_train['overall'])

y_pred_entropy_2 = dt_entropy.predict(X_val_bow_summary)
accuracy_entropy_2 = metrics.accuracy_score(df_val['overall'], y_pred_entropy_2)

dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini.fit(X_train_bow_summary, df_train['overall'])

y_pred_gini_2 = dt_gini.predict(X_val_bow_summary)
accuracy_gini_2 = metrics.accuracy_score(df_val['overall'], y_pred_gini_2)

print("Decision Tree Accuracy with Entropy on Validation Set:", accuracy_entropy_2)
print("Decision Tree Accuracy with Gini on Validation Set:", accuracy_gini_2)

print("\nDecision Tree Metrics (Entropy):")
print("Accuracy:", accuracy_entropy_2)
print("Precision:", precision_score(df_val['overall'], y_pred_entropy_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_entropy_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_entropy_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_entropy_2))

print("\nDecision Tree Metrics (Gini):")
print("Accuracy:", accuracy_gini_2)
print("Precision:", precision_score(df_val['overall'], y_pred_gini_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gini_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gini_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gini_2))

"""tfidf + review + summary"""

df_train['processed_reviewText'].fillna('', inplace=True)
df_train['processed_summary'].fillna('', inplace=True)

df_val['processed_reviewText'].fillna('', inplace=True)
df_val['processed_summary'].fillna('', inplace=True)

vectorizer_review = TfidfVectorizer()
vectorizer_summary = TfidfVectorizer()

X_train_tfidf_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_train_tfidf_summary = vectorizer_summary.fit_transform(df_train['processed_summary'])

X_val_tfidf_review = vectorizer_review.transform(df_val['processed_reviewText'])
X_val_tfidf_summary = vectorizer_summary.transform(df_val['processed_summary'])

X_train_tfidf_combined = hstack([X_train_tfidf_review, X_train_tfidf_summary])
X_val_tfidf_combined = hstack([X_val_tfidf_review, X_val_tfidf_summary])

dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy.fit(X_train_tfidf_combined, df_train['overall'])

y_pred_entropy_3 = dt_entropy.predict(X_val_tfidf_combined)
accuracy_entropy_3 = metrics.accuracy_score(df_val['overall'], y_pred_entropy_3)

dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini.fit(X_train_tfidf_combined, df_train['overall'])

y_pred_gini_3 = dt_gini.predict(X_val_tfidf_combined)
accuracy_gini_3 = metrics.accuracy_score(df_val['overall'], y_pred_gini_3)

print("Decision Tree Accuracy with Entropy on Validation Set:", accuracy_entropy_3)
print("Decision Tree Accuracy with Gini on Validation Set:", accuracy_gini_3)

print("\nDecision Tree Metrics (Entropy):")
print("Accuracy:", accuracy_entropy_3)
print("Precision:", precision_score(df_val['overall'], y_pred_entropy_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_entropy_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_entropy_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_entropy_3))

print("\nDecision Tree Metrics (Gini):")
print("Accuracy:", accuracy_gini_3)
print("Precision:", precision_score(df_val['overall'], y_pred_gini_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_gini_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_gini_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_gini_3))

"""## Random Forest

bow + review
"""

vectorizer_review = CountVectorizer()

X_train_bow_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_val_bow_review = vectorizer_review.transform(df_val['processed_reviewText'])

rf_20_trees = RandomForestClassifier(n_estimators=20, random_state=42)
rf_20_trees.fit(X_train_bow_review, df_train['overall'])

y_pred_20_trees_1 = rf_20_trees.predict(X_val_bow_review)
accuracy_20_trees_1 = metrics.accuracy_score(df_val['overall'], y_pred_20_trees_1)

rf_50_trees = RandomForestClassifier(n_estimators=50, random_state=42)
rf_50_trees.fit(X_train_bow_review, df_train['overall'])

y_pred_50_trees_1 = rf_50_trees.predict(X_val_bow_review)
accuracy_50_trees_1 = metrics.accuracy_score(df_val['overall'], y_pred_50_trees_1)

rf_100_trees = RandomForestClassifier(n_estimators=100, random_state=42)
rf_100_trees.fit(X_train_bow_review, df_train['overall'])

y_pred_100_trees_1 = rf_100_trees.predict(X_val_bow_review)
accuracy_100_trees_1 = metrics.accuracy_score(df_val['overall'], y_pred_100_trees_1)

print("Random Forest Accuracy with 20 Trees on Validation Set:", accuracy_20_trees_1)
print("Random Forest Accuracy with 50 Trees on Validation Set:", accuracy_50_trees_1)
print("Random Forest Accuracy with 100 Trees on Validation Set:", accuracy_100_trees_1)

print("\nRandom Forest Metrics (20 Trees):")
print("Accuracy:", accuracy_20_trees_1)
print("Precision:", precision_score(df_val['overall'], y_pred_20_trees_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_20_trees_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_20_trees_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_20_trees_1))

print("\nRandom Forest Metrics (50 Trees):")
print("Accuracy:", accuracy_50_trees_1)
print("Precision:", precision_score(df_val['overall'], y_pred_50_trees_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_50_trees_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_50_trees_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_50_trees_1))

print("\nRandom Forest Metrics (100 Trees):")
print("Accuracy:", accuracy_100_trees_1)
print("Precision:", precision_score(df_val['overall'], y_pred_100_trees_1, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_100_trees_1, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_100_trees_1, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_100_trees_1))

"""bow + summary"""

vectorizer_summary = CountVectorizer()

X_train_bow_summary = vectorizer_summary.fit_transform(df_train['processed_summary'])
X_val_bow_summary = vectorizer_summary.transform(df_val['processed_summary'])

rf_20_trees = RandomForestClassifier(n_estimators=20, random_state=42)
rf_20_trees.fit(X_train_bow_summary, df_train['overall'])

y_pred_20_trees_2 = rf_20_trees.predict(X_val_bow_summary)
accuracy_20_trees_2 = metrics.accuracy_score(df_val['overall'], y_pred_20_trees_2)

rf_50_trees = RandomForestClassifier(n_estimators=50, random_state=42)
rf_50_trees.fit(X_train_bow_summary, df_train['overall'])
y_pred_50_trees_2 = rf_50_trees.predict(X_val_bow_summary)
accuracy_50_trees_2 = metrics.accuracy_score(df_val['overall'], y_pred_50_trees_2)

rf_100_trees = RandomForestClassifier(n_estimators=100, random_state=42)
rf_100_trees.fit(X_train_bow_summary, df_train['overall'])
y_pred_100_trees_2 = rf_100_trees.predict(X_val_bow_summary)
accuracy_100_trees_2 = metrics.accuracy_score(df_val['overall'], y_pred_100_trees_2)

print("Random Forest Accuracy with 20 Trees on Validation Set:", accuracy_20_trees_2)
print("Random Forest Accuracy with 50 Trees on Validation Set:", accuracy_50_trees_2)
print("Random Forest Accuracy with 100 Trees on Validation Set:", accuracy_100_trees_2)

print("\nRandom Forest Metrics (20 Trees):")
print("Accuracy:", accuracy_20_trees_2)
print("Precision:", precision_score(df_val['overall'], y_pred_20_trees_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_20_trees_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_20_trees_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_20_trees_2))

print("\nRandom Forest Metrics (50 Trees):")
print("Accuracy:", accuracy_50_trees_2)
print("Precision:", precision_score(df_val['overall'], y_pred_50_trees_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_50_trees_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_50_trees_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_50_trees_2))

print("\nRandom Forest Metrics (100 Trees):")
print("Accuracy:", accuracy_100_trees_2)
print("Precision:", precision_score(df_val['overall'], y_pred_100_trees_2, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_100_trees_2, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_100_trees_2, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_100_trees_2))

"""tfidf + review + summary"""

df_train['processed_reviewText'].fillna('', inplace=True)
df_train['processed_summary'].fillna('', inplace=True)

df_val['processed_reviewText'].fillna('', inplace=True)
df_val['processed_summary'].fillna('', inplace=True)
vectorizer_review = TfidfVectorizer()
vectorizer_summary = TfidfVectorizer()

X_train_tfidf_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_train_tfidf_summary = vectorizer_summary.fit_transform(df_train['processed_summary'])

X_val_tfidf_review = vectorizer_review.transform(df_val['processed_reviewText'])
X_val_tfidf_summary = vectorizer_summary.transform(df_val['processed_summary'])
X_train_tfidf_combined = hstack([X_train_tfidf_review, X_train_tfidf_summary])
X_val_tfidf_combined = hstack([X_val_tfidf_review, X_val_tfidf_summary])
rf_20_trees = RandomForestClassifier(n_estimators=20, random_state=42)
rf_20_trees.fit(X_train_tfidf_combined, df_train['overall'])
y_pred_20_trees_3 = rf_20_trees.predict(X_val_tfidf_combined)
accuracy_20_trees_3 = metrics.accuracy_score(df_val['overall'], y_pred_20_trees_3)
rf_50_trees = RandomForestClassifier(n_estimators=50, random_state=42)
rf_50_trees.fit(X_train_tfidf_combined, df_train['overall'])
y_pred_50_trees_3 = rf_50_trees.predict(X_val_tfidf_combined)
accuracy_50_trees_3 = metrics.accuracy_score(df_val['overall'], y_pred_50_trees_3)
rf_100_trees = RandomForestClassifier(n_estimators=100, random_state=42)
rf_100_trees.fit(X_train_tfidf_combined, df_train['overall'])
y_pred_100_trees_3 = rf_100_trees.predict(X_val_tfidf_combined)
accuracy_100_trees_3 = metrics.accuracy_score(df_val['overall'], y_pred_100_trees_3)
print("Random Forest Accuracy with 20 Trees on Validation Set:", accuracy_20_trees_3)
print("Random Forest Accuracy with 50 Trees on Validation Set:", accuracy_50_trees_3)
print("Random Forest Accuracy with 100 Trees on Validation Set:", accuracy_100_trees_3)

print("\nRandom Forest Metrics (20 Trees):")
print("Accuracy:", accuracy_20_trees_3)
print("Precision:", precision_score(df_val['overall'], y_pred_20_trees_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_20_trees_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_20_trees_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_20_trees_3))

print("\nRandom Forest Metrics (50 Trees):")
print("Accuracy:", accuracy_50_trees_3)
print("Precision:", precision_score(df_val['overall'], y_pred_50_trees_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_50_trees_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_50_trees_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_50_trees_3))

print("\nRandom Forest Metrics (100 Trees):")
print("Accuracy:", accuracy_100_trees_3)
print("Precision:", precision_score(df_val['overall'], y_pred_100_trees_3, average='weighted'))
print("Recall:", recall_score(df_val['overall'], y_pred_100_trees_3, average='weighted'))
print("F1 Score:", f1_score(df_val['overall'], y_pred_100_trees_3, average='weighted'))
print("Confusion Matrix:\n", confusion_matrix(df_val['overall'], y_pred_100_trees_3))

"""# Binary clasification"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc

"""Bag-of-Words (CountVectorizer) with Naive Bayes"""

df_train['binary_target'] = df_train['overall'].apply(lambda x: 'NEGATIVE' if x in [1.0, 2.0] else 'POSITIVE')
df_val['binary_target'] = df_val['overall'].apply(lambda x: 'NEGATIVE' if x in [1.0, 2.0] else 'POSITIVE')

gnb_binary = GaussianNB()
gnb_binary.fit(X_train_bow.toarray(), df_train['binary_target'])
y_pred_gaussian_binary_1 = gnb_binary.predict(X_val_bow.toarray())
accuracy_gaussian_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_gaussian_binary_1)

mnb_binary = MultinomialNB()
mnb_binary.fit(X_train_bow, df_train['binary_target'])
y_pred_multinomial_binary_1 = mnb_binary.predict(X_val_bow)
accuracy_multinomial_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_multinomial_binary_1)

print("Gaussian Naive Bayes Accuracy (Binary Classification):", accuracy_gaussian_binary_1)
print("Multinomial Naive Bayes Accuracy (Binary Classification):", accuracy_multinomial_binary_1)

precision_gaussian_binary_1 = precision_score(df_val['binary_target'], y_pred_gaussian_binary_1, pos_label='POSITIVE')
recall_gaussian_binary_1 = recall_score(df_val['binary_target'], y_pred_gaussian_binary_1, pos_label='POSITIVE')
f1_gaussian_binary_1 = f1_score(df_val['binary_target'], y_pred_gaussian_binary_1, pos_label='POSITIVE')
conf_matrix_gaussian_binary_1 = confusion_matrix(df_val['binary_target'], y_pred_gaussian_binary_1)

print("Gaussian Naive Bayes Accuracy (Binary Classification):", accuracy_gaussian_binary_1)
print("Precision (Binary Classification):", precision_gaussian_binary_1)
print("Recall (Binary Classification):", recall_gaussian_binary_1)
print("F1 Score (Binary Classification):", f1_gaussian_binary_1)
print("Confusion Matrix:")
print(conf_matrix_gaussian_binary_1)

precision_multinomial_binary_1 = precision_score(df_val['binary_target'], y_pred_multinomial_binary_1, pos_label='POSITIVE')
recall_multinomial_binary_1 = recall_score(df_val['binary_target'], y_pred_multinomial_binary_1, pos_label='POSITIVE')
f1_multinomial_binary_1 = f1_score(df_val['binary_target'], y_pred_multinomial_binary_1, pos_label='POSITIVE')
conf_matrix_multinomial_binary_1 = confusion_matrix(df_val['binary_target'], y_pred_multinomial_binary_1)

print("\nMultinomial Naive Bayes Accuracy (Binary Classification):", accuracy_multinomial_binary_1)
print("Precision (Binary Classification):", precision_multinomial_binary_1)
print("Recall (Binary Classification):", recall_multinomial_binary_1)
print("F1 Score (Binary Classification):", f1_multinomial_binary_1)
print("Confusion Matrix:")
print(conf_matrix_multinomial_binary_1)

"""TF-IDF with Naive Bayes"""

gnb_binary = GaussianNB()
gnb_binary.fit(X_train_tfidf_combined.toarray(), df_train['binary_target'])
y_pred_gaussian_binary_2 = gnb_binary.predict(X_val_tfidf_combined.toarray())
accuracy_gaussian_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_gaussian_binary_2)

mnb_binary = MultinomialNB()
mnb_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_multinomial_binary_2 = mnb_binary.predict(X_val_tfidf_combined)
accuracy_multinomial_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_multinomial_binary_2)

print("Gaussian Naive Bayes Accuracy with TF-IDF (Binary Classification):", accuracy_gaussian_binary_2)
print("Multinomial Naive Bayes Accuracy with TF-IDF (Binary Classification):", accuracy_multinomial_binary_2)

precision_gaussian_binary_2 = precision_score(df_val['binary_target'], y_pred_gaussian_binary_2, pos_label='POSITIVE')
recall_gaussian_binary_2 = recall_score(df_val['binary_target'], y_pred_gaussian_binary_2, pos_label='POSITIVE')
f1_gaussian_binary_2 = f1_score(df_val['binary_target'], y_pred_gaussian_binary_2, pos_label='POSITIVE')
conf_matrix_gaussian_binary_2 = confusion_matrix(df_val['binary_target'], y_pred_gaussian_binary_2)

print("Gaussian Naive Bayes Accuracy with TF-IDF (Binary Classification):", accuracy_gaussian_binary_2)
print("Precision (Binary Classification):", precision_gaussian_binary_2)
print("Recall (Binary Classification):", recall_gaussian_binary_2)
print("F1 Score (Binary Classification):", f1_gaussian_binary_2)
print("Confusion Matrix:")
print(conf_matrix_gaussian_binary_2)

precision_multinomial_binary_2 = precision_score(df_val['binary_target'], y_pred_multinomial_binary_2, pos_label='POSITIVE')
recall_multinomial_binary_2 = recall_score(df_val['binary_target'], y_pred_multinomial_binary_2, pos_label='POSITIVE')
f1_multinomial_binary_2 = f1_score(df_val['binary_target'], y_pred_multinomial_binary_2, pos_label='POSITIVE')
conf_matrix_multinomial_binary_2 = confusion_matrix(df_val['binary_target'], y_pred_multinomial_binary_2)

print("\nMultinomial Naive Bayes Accuracy with TF-IDF (Binary Classification):", accuracy_multinomial_binary_2)
print("Precision (Binary Classification):", precision_multinomial_binary_2)
print("Recall (Binary Classification):", recall_multinomial_binary_2)
print("F1 Score (Binary Classification):", f1_multinomial_binary_2)
print("Confusion Matrix:")
print(conf_matrix_multinomial_binary_2)

"""Bag-of-Words with Decision Tree"""

dt_entropy_binary = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy_binary.fit(X_train_bow_review, df_train['binary_target'])
y_pred_entropy_binary_1 = dt_entropy_binary.predict(X_val_bow_review)
accuracy_entropy_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_entropy_binary_1)
conf_matrix_entropy_binary_1 = metrics.confusion_matrix(df_val['binary_target'], y_pred_entropy_binary_1)

dt_gini_binary = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini_binary.fit(X_train_bow_review, df_train['binary_target'])
y_pred_gini_binary_1 = dt_gini_binary.predict(X_val_bow_review)
accuracy_gini_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_gini_binary_1)
conf_matrix_gini_binary_1 = metrics.confusion_matrix(df_val['binary_target'], y_pred_gini_binary_1)

print("Decision Tree Accuracy with Entropy (Binary Classification):", accuracy_entropy_binary_1)
print("Confusion Matrix:")
print(conf_matrix_entropy_binary_1)

print("Decision Tree Accuracy with Gini (Binary Classification):", accuracy_gini_binary_1)
print("Confusion Matrix:")
print(conf_matrix_gini_binary_1)

"""TF-IDF with Decision Tree"""

dt_entropy_binary = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_entropy_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_entropy_binary_2 = dt_entropy_binary.predict(X_val_tfidf_combined)
accuracy_entropy_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_entropy_binary_2)
conf_matrix_entropy_binary_2 = metrics.confusion_matrix(df_val['binary_target'], y_pred_entropy_binary_2)

dt_gini_binary = DecisionTreeClassifier(criterion='gini', random_state=42)
dt_gini_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_gini_binary_2 = dt_gini_binary.predict(X_val_tfidf_combined)
accuracy_gini_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_gini_binary_2)
conf_matrix_gini_binary_2 = metrics.confusion_matrix(df_val['binary_target'], y_pred_gini_binary_2)

print("Decision Tree Accuracy with Entropy (Binary Classification):", accuracy_entropy_binary_2)
print("Confusion Matrix:")
print(conf_matrix_entropy_binary_2)

print("Decision Tree Accuracy with Gini (Binary Classification):", accuracy_gini_binary_2)
print("Confusion Matrix:")
print(conf_matrix_gini_binary_2)

sns.set(style="whitegrid")

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix_entropy_binary_1, annot=True, fmt='d', cmap="Blues", annot_kws={"size": 16})
plt.title("Decision Tree with Entropy - Confusion Matrix (Binary Classification)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 2, 2)
sns.heatmap(conf_matrix_gini_binary_1, annot=True, fmt='d', cmap="Blues", annot_kws={"size": 16})
plt.title("Decision Tree with Gini - Confusion Matrix (Binary Classification)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()

"""Bag-of-Words with Random Forest"""

vectorizer_review = CountVectorizer()

X_train_bow_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_val_bow_review = vectorizer_review.transform(df_val['processed_reviewText'])

rf_20_trees_binary = RandomForestClassifier(n_estimators=20, random_state=42)
rf_20_trees_binary.fit(X_train_bow_review, df_train['binary_target'])
y_pred_20_trees_binary_1 = rf_20_trees_binary.predict(X_val_bow_review)
accuracy_20_trees_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_20_trees_binary_1)
conf_matrix_20_trees_binary_1 = metrics.confusion_matrix(df_val['binary_target'], y_pred_20_trees_binary_1)

rf_50_trees_binary = RandomForestClassifier(n_estimators=50, random_state=42)
rf_50_trees_binary.fit(X_train_bow_review, df_train['binary_target'])
y_pred_50_trees_binary_1 = rf_50_trees_binary.predict(X_val_bow_review)
accuracy_50_trees_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_50_trees_binary_1)
conf_matrix_50_trees_binary_1 = metrics.confusion_matrix(df_val['binary_target'], y_pred_50_trees_binary_1)

rf_100_trees_binary = RandomForestClassifier(n_estimators=100, random_state=42)
rf_100_trees_binary.fit(X_train_bow_review, df_train['binary_target'])
y_pred_100_trees_binary_1 = rf_100_trees_binary.predict(X_val_bow_review)
accuracy_100_trees_binary_1 = metrics.accuracy_score(df_val['binary_target'], y_pred_100_trees_binary_1)
conf_matrix_100_trees_binary_1 = metrics.confusion_matrix(df_val['binary_target'], y_pred_100_trees_binary_1)

print("Random Forest Accuracy with 20 Trees (Binary Classification):", accuracy_20_trees_binary_1)
print("Confusion Matrix:")
print(conf_matrix_20_trees_binary_1)

print("Random Forest Accuracy with 50 Trees (Binary Classification):", accuracy_50_trees_binary_1)
print("Confusion Matrix:")
print(conf_matrix_50_trees_binary_1)

print("Random Forest Accuracy with 100 Trees (Binary Classification):", accuracy_100_trees_binary_1)
print("Confusion Matrix:")
print(conf_matrix_100_trees_binary_1)

"""TF-IDF with Random Forest"""

vectorizer_review = TfidfVectorizer()

X_train_tfidf_review = vectorizer_review.fit_transform(df_train['processed_reviewText'])
X_val_tfidf_review = vectorizer_review.transform(df_val['processed_reviewText'])

df_train['binary_target'] = df_train['overall'].apply(lambda x: 0 if x in [1.0, 2.0] else 1)
df_val['binary_target'] = df_val['overall'].apply(lambda x: 0 if x in [1.0, 2.0] else 1)

X_train_tfidf_combined = hstack([X_train_tfidf_review])
X_val_tfidf_combined = hstack([X_val_tfidf_review])

rf_20_trees_binary = RandomForestClassifier(n_estimators=20, random_state=42)
rf_20_trees_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_20_trees_binary_2 = rf_20_trees_binary.predict(X_val_tfidf_combined)
accuracy_20_trees_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_20_trees_binary_2)
conf_matrix_20_trees_binary_2 = metrics.confusion_matrix(df_val['binary_target'], y_pred_20_trees_binary_2)

rf_50_trees_binary = RandomForestClassifier(n_estimators=50, random_state=42)
rf_50_trees_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_50_trees_binary_2 = rf_50_trees_binary.predict(X_val_tfidf_combined)
accuracy_50_trees_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_50_trees_binary_2)
conf_matrix_50_trees_binary_2 = metrics.confusion_matrix(df_val['binary_target'], y_pred_50_trees_binary_2)

rf_100_trees_binary = RandomForestClassifier(n_estimators=100, random_state=42)
rf_100_trees_binary.fit(X_train_tfidf_combined, df_train['binary_target'])
y_pred_100_trees_binary_2 = rf_100_trees_binary.predict(X_val_tfidf_combined)
accuracy_100_trees_binary_2 = metrics.accuracy_score(df_val['binary_target'], y_pred_100_trees_binary_2)
conf_matrix_100_trees_binary_2 = metrics.confusion_matrix(df_val['binary_target'], y_pred_100_trees_binary_2)

print("Random Forest Accuracy with 20 Trees (Binary Classification):", accuracy_20_trees_binary_2)
print("Confusion Matrix:")
print(conf_matrix_20_trees_binary_2)

print("Random Forest Accuracy with 50 Trees (Binary Classification):", accuracy_50_trees_binary_2)
print("Confusion Matrix:")
print(conf_matrix_50_trees_binary_2)

print("Random Forest Accuracy with 100 Trees (Binary Classification):", accuracy_100_trees_binary_2)
print("Confusion Matrix:")
print(conf_matrix_100_trees_binary_2)

plt.figure(figsize=(18, 5))

plt.subplot(1, 3, 1)
sns.heatmap(conf_matrix_20_trees_binary_1, annot=True, fmt='d', cmap="Greens", annot_kws={"size": 16})
plt.title("Random Forest (20 Trees) - Confusion Matrix (Binary Classification)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 3, 2)
sns.heatmap(conf_matrix_50_trees_binary_1, annot=True, fmt='d', cmap="Greens", annot_kws={"size": 16})
plt.title("Random Forest (50 Trees) - Confusion Matrix (Binary Classification)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 3, 3)
sns.heatmap(conf_matrix_100_trees_binary_1, annot=True, fmt='d', cmap="Greens", annot_kws={"size": 16})
plt.title("Random Forest (100 Trees) - Confusion Matrix (Binary Classification)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()

y_score_rf_100_trees = rf_100_trees_binary.predict_proba(X_val_bow_review)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(df_val['binary_target'], y_score_rf_100_trees)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='Random Forest (100 Trees) - ROC curve (area = {:.2f})'.format(roc_auc_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic - Binary Classification')
plt.legend(loc="lower right")
plt.show()

models = ['Gaussian Naive Bayes (BoW)', 'Multinomial Naive Bayes (BoW)',
          'Gaussian Naive Bayes (TF-IDF)', 'Multinomial Naive Bayes (TF-IDF)',
          'Decision Tree (Entropy)', 'Decision Tree (Gini)',
          'Random Forest (20 Trees)', 'Random Forest (50 Trees)', 'Random Forest (100 Trees)']

accuracies = [accuracy_gaussian_binary_1, accuracy_multinomial_binary_1,+
              accuracy_gaussian_binary_2, accuracy_multinomial_binary_2,
              accuracy_entropy_binary_1, accuracy_gini_binary_1,
              accuracy_20_trees_binary_1, accuracy_50_trees_binary_1, accuracy_100_trees_binary_1]

plt.figure(figsize=(12, 6))
plt.barh(models, accuracies, color='skyblue')
plt.xlabel('Accuracy')
plt.title('Model Accuracy Comparison - Binary Classification')
plt.xlim(0, 1.0)
plt.show()

